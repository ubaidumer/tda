"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.getVulnerabilityAlerts = exports.massageMarkdown = exports.mergePr = exports.updatePr = exports.createPr = exports.ensureCommentRemoval = exports.ensureComment = exports.deleteLabel = exports.addReviewers = exports.addAssignees = exports.ensureIssueClosing = exports.ensureIssue = exports.findIssue = exports.getIssue = exports.getIssueList = exports.setBranchStatus = exports.getBranchStatusCheck = exports.getBranchStatus = exports.getBranchPr = exports.findPr = exports.getPrList = exports.getPr = exports.getRepoForceRebase = exports.initRepo = exports.getJsonFile = exports.getRawFile = exports.getRepos = exports.initPlatform = exports.detectGhe = void 0;
const tslib_1 = require("tslib");
const url_1 = (0, tslib_1.__importDefault)(require("url"));
const is_1 = (0, tslib_1.__importDefault)(require("@sindresorhus/is"));
const delay_1 = (0, tslib_1.__importDefault)(require("delay"));
const json5_1 = (0, tslib_1.__importDefault)(require("json5"));
const luxon_1 = require("luxon");
const semver_1 = require("semver");
const error_messages_1 = require("../../constants/error-messages");
const logger_1 = require("../../logger");
const types_1 = require("../../types");
const external_host_error_1 = require("../../types/errors/external-host-error");
const git = (0, tslib_1.__importStar)(require("../../util/git"));
const hostRules = (0, tslib_1.__importStar)(require("../../util/host-rules"));
const githubHttp = (0, tslib_1.__importStar)(require("../../util/http/github"));
const regex_1 = require("../../util/regex");
const sanitize_1 = require("../../util/sanitize");
const url_2 = require("../../util/url");
const pr_body_1 = require("../utils/pr-body");
const graphql_1 = require("./graphql");
const massage_markdown_links_1 = require("./massage-markdown-links");
const user_1 = require("./user");
const githubApi = new githubHttp.GithubHttp();
let config = {};
const platformConfig = {
    hostType: "github" /* Github */,
    endpoint: 'https://api.github.com/',
};
const escapeHash = (input) => input ? input.replace((0, regex_1.regEx)(/#/g), '%23') : input;
async function detectGhe(token) {
    var _a, _b;
    platformConfig.isGhe =
        url_1.default.parse(platformConfig.endpoint).host !== 'api.github.com';
    if (platformConfig.isGhe) {
        const gheHeaderKey = 'x-github-enterprise-version';
        const gheQueryRes = await githubApi.headJson('/', { token });
        const gheHeaders = (gheQueryRes === null || gheQueryRes === void 0 ? void 0 : gheQueryRes.headers) || {};
        const [, gheVersion] = (_a = Object.entries(gheHeaders).find(([k]) => k.toLowerCase() === gheHeaderKey)) !== null && _a !== void 0 ? _a : [];
        platformConfig.gheVersion = (_b = (0, semver_1.valid)(gheVersion)) !== null && _b !== void 0 ? _b : null;
    }
}
exports.detectGhe = detectGhe;
async function initPlatform({ endpoint, token, username, gitAuthor, }) {
    if (!token) {
        throw new Error('Init: You must configure a GitHub personal access token');
    }
    if (endpoint) {
        platformConfig.endpoint = (0, url_2.ensureTrailingSlash)(endpoint);
        githubHttp.setBaseUrl(platformConfig.endpoint);
    }
    else {
        logger_1.logger.debug('Using default github endpoint: ' + platformConfig.endpoint);
    }
    await detectGhe(token);
    let userDetails;
    let renovateUsername;
    if (username) {
        renovateUsername = username;
    }
    else {
        userDetails = await (0, user_1.getUserDetails)(platformConfig.endpoint, token);
        renovateUsername = userDetails.username;
    }
    let discoveredGitAuthor;
    if (!gitAuthor) {
        userDetails = await (0, user_1.getUserDetails)(platformConfig.endpoint, token);
        const userEmail = await (0, user_1.getUserEmail)(platformConfig.endpoint, token);
        if (userEmail) {
            discoveredGitAuthor = `${userDetails.name} <${userEmail}>`;
        }
    }
    logger_1.logger.debug({ platformConfig, renovateUsername }, 'Platform config');
    const platformResult = {
        endpoint: platformConfig.endpoint,
        gitAuthor: gitAuthor || discoveredGitAuthor,
        renovateUsername,
    };
    return platformResult;
}
exports.initPlatform = initPlatform;
// Get all repositories that the user has access to
async function getRepos() {
    logger_1.logger.debug('Autodiscovering GitHub repositories');
    try {
        const res = await githubApi.getJson('user/repos?per_page=100', { paginate: 'all' });
        return res.body.map((repo) => repo.full_name);
    }
    catch (err) /* istanbul ignore next */ {
        logger_1.logger.error({ err }, `GitHub getRepos error`);
        throw err;
    }
}
exports.getRepos = getRepos;
async function getBranchProtection(branchName) {
    // istanbul ignore if
    if (config.parentRepo) {
        return {};
    }
    const res = await githubApi.getJson(`repos/${config.repository}/branches/${escapeHash(branchName)}/protection`);
    return res.body;
}
async function getRawFile(fileName, repoName, branchOrTag) {
    const repo = repoName !== null && repoName !== void 0 ? repoName : config.repository;
    let url = `repos/${repo}/contents/${fileName}`;
    if (branchOrTag) {
        url += `?ref=` + branchOrTag;
    }
    const res = await githubApi.getJson(url);
    const buf = res.body.content;
    const str = Buffer.from(buf, 'base64').toString();
    return str;
}
exports.getRawFile = getRawFile;
async function getJsonFile(fileName, repoName, branchOrTag) {
    const raw = await getRawFile(fileName, repoName, branchOrTag);
    if (fileName.endsWith('.json5')) {
        return json5_1.default.parse(raw);
    }
    return JSON.parse(raw);
}
exports.getJsonFile = getJsonFile;
let existingRepos;
// Initialize GitHub by getting base branch and SHA
async function initRepo({ endpoint, repository, forkMode, forkToken, renovateUsername, cloneSubmodules, ignorePrAuthor, }) {
    var _a, _b, _c, _d, _e, _f;
    logger_1.logger.debug(`initRepo("${repository}")`);
    // config is used by the platform api itself, not necessary for the app layer to know
    config = {
        repository,
        cloneSubmodules,
        ignorePrAuthor,
    };
    // istanbul ignore if
    if (endpoint) {
        // Necessary for Renovate Pro - do not remove
        logger_1.logger.debug({ endpoint }, 'Overriding default GitHub endpoint');
        platformConfig.endpoint = endpoint;
        githubHttp.setBaseUrl(endpoint);
    }
    const opts = hostRules.find({
        hostType: "github" /* Github */,
        url: platformConfig.endpoint,
    });
    config.renovateUsername = renovateUsername;
    [config.repositoryOwner, config.repositoryName] = repository.split('/');
    let repo;
    try {
        let infoQuery = graphql_1.repoInfoQuery;
        if (platformConfig.isGhe) {
            infoQuery = infoQuery.replace(/\n\s*autoMergeAllowed\s*\n/, '\n');
            infoQuery = infoQuery.replace(/\n\s*hasIssuesEnabled\s*\n/, '\n');
        }
        const res = await githubApi.requestGraphql(infoQuery, {
            variables: {
                owner: config.repositoryOwner,
                name: config.repositoryName,
            },
        });
        repo = (_a = res === null || res === void 0 ? void 0 : res.data) === null || _a === void 0 ? void 0 : _a.repository;
        // istanbul ignore if
        if (!repo) {
            throw new Error(error_messages_1.REPOSITORY_NOT_FOUND);
        }
        // istanbul ignore if
        if (!((_b = repo.defaultBranchRef) === null || _b === void 0 ? void 0 : _b.name)) {
            throw new Error(error_messages_1.REPOSITORY_EMPTY);
        }
        if (repo.nameWithOwner && repo.nameWithOwner !== repository) {
            logger_1.logger.debug({ repository, this_repository: repo.nameWithOwner }, 'Repository has been renamed');
            throw new Error(error_messages_1.REPOSITORY_RENAMED);
        }
        if (repo.isArchived) {
            logger_1.logger.debug('Repository is archived - throwing error to abort renovation');
            throw new Error(error_messages_1.REPOSITORY_ARCHIVED);
        }
        // Use default branch as PR target unless later overridden.
        config.defaultBranch = repo.defaultBranchRef.name;
        // Base branch may be configured but defaultBranch is always fixed
        logger_1.logger.debug(`${repository} default branch = ${config.defaultBranch}`);
        // GitHub allows administrators to block certain types of merge, so we need to check it
        if (repo.rebaseMergeAllowed) {
            config.mergeMethod = 'rebase';
        }
        else if (repo.squashMergeAllowed) {
            config.mergeMethod = 'squash';
        }
        else if (repo.mergeCommitAllowed) {
            config.mergeMethod = 'merge';
        }
        else {
            // This happens if we don't have Administrator read access, it is not a critical error
            logger_1.logger.debug('Could not find allowed merge methods for repo');
        }
        config.autoMergeAllowed = repo.autoMergeAllowed;
        config.hasIssuesEnabled = repo.hasIssuesEnabled;
    }
    catch (err) /* istanbul ignore next */ {
        logger_1.logger.debug({ err }, 'Caught initRepo error');
        if (err.message === error_messages_1.REPOSITORY_ARCHIVED ||
            err.message === error_messages_1.REPOSITORY_RENAMED ||
            err.message === error_messages_1.REPOSITORY_NOT_FOUND) {
            throw err;
        }
        if (err.statusCode === 403) {
            throw new Error(error_messages_1.REPOSITORY_ACCESS_FORBIDDEN);
        }
        if (err.statusCode === 404) {
            throw new Error(error_messages_1.REPOSITORY_NOT_FOUND);
        }
        if (err.message.startsWith('Repository access blocked')) {
            throw new Error(error_messages_1.REPOSITORY_BLOCKED);
        }
        if (err.message === error_messages_1.REPOSITORY_FORKED) {
            throw err;
        }
        if (err.message === error_messages_1.REPOSITORY_DISABLED) {
            throw err;
        }
        if (err.message === 'Response code 451 (Unavailable for Legal Reasons)') {
            throw new Error(error_messages_1.REPOSITORY_ACCESS_FORBIDDEN);
        }
        logger_1.logger.debug({ err }, 'Unknown GitHub initRepo error');
        throw err;
    }
    // This shouldn't be necessary, but occasional strange errors happened until it was added
    config.issueList = null;
    config.prList = null;
    config.openPrList = null;
    config.closedPrList = null;
    config.branchPrs = [];
    config.forkMode = !!forkMode;
    if (forkMode) {
        logger_1.logger.debug('Bot is in forkMode');
        config.forkToken = forkToken;
        // save parent name then delete
        config.parentRepo = config.repository;
        config.repository = null;
        // Get list of existing repos
        existingRepos =
            existingRepos ||
                (await githubApi.getJson('user/repos?per_page=100', {
                    token: forkToken || opts.token,
                    paginate: true,
                    pageLimit: 100,
                })).body.map((r) => r.full_name);
        try {
            const forkedRepo = await githubApi.postJson(`repos/${repository}/forks`, {
                token: forkToken || opts.token,
            });
            config.repository = forkedRepo.body.full_name;
            const forkDefaultBranch = forkedRepo.body.default_branch;
            if (forkDefaultBranch !== config.defaultBranch) {
                const body = {
                    ref: `refs/heads/${config.defaultBranch}`,
                    sha: repo.defaultBranchRef.target.oid,
                };
                logger_1.logger.debug({
                    defaultBranch: config.defaultBranch,
                    forkDefaultBranch,
                    body,
                }, 'Fork has different default branch to parent, attempting to create branch');
                try {
                    await githubApi.postJson(`repos/${config.repository}/git/refs`, {
                        body,
                        token: forkToken,
                    });
                    logger_1.logger.debug('Created new default branch in fork');
                }
                catch (err) /* istanbul ignore next */ {
                    if (((_d = (_c = err.response) === null || _c === void 0 ? void 0 : _c.body) === null || _d === void 0 ? void 0 : _d.message) === 'Reference already exists') {
                        logger_1.logger.debug(`Branch ${config.defaultBranch} already exists in the fork`);
                    }
                    else {
                        logger_1.logger.warn({ err, body: (_e = err.response) === null || _e === void 0 ? void 0 : _e.body }, 'Could not create parent defaultBranch in fork');
                    }
                }
                logger_1.logger.debug(`Setting ${config.defaultBranch} as default branch for ${config.repository}`);
                try {
                    await githubApi.patchJson(`repos/${config.repository}`, {
                        body: {
                            name: config.repository.split('/')[1],
                            default_branch: config.defaultBranch,
                        },
                        token: forkToken,
                    });
                    logger_1.logger.debug('Successfully changed default branch for fork');
                }
                catch (err) /* istanbul ignore next */ {
                    logger_1.logger.warn({ err }, 'Could not set default branch');
                }
            }
        }
        catch (err) /* istanbul ignore next */ {
            logger_1.logger.debug({ err }, 'Error forking repository');
            throw new Error(error_messages_1.REPOSITORY_CANNOT_FORK);
        }
        if (existingRepos.includes(config.repository)) {
            logger_1.logger.debug({ repository_fork: config.repository }, 'Found existing fork');
            // This is a lovely "hack" by GitHub that lets us force update our fork's default branch
            // with the base commit from the parent repository
            try {
                logger_1.logger.debug('Updating forked repository default sha to match upstream');
                await githubApi.patchJson(`repos/${config.repository}/git/refs/heads/${config.defaultBranch}`, {
                    body: {
                        sha: repo.defaultBranchRef.target.oid,
                        force: true,
                    },
                    token: forkToken || opts.token,
                });
            }
            catch (err) /* istanbul ignore next */ {
                logger_1.logger.warn({ err: err.err || err }, 'Error updating fork from upstream - cannot continue');
                if (err instanceof external_host_error_1.ExternalHostError) {
                    throw err;
                }
                throw new external_host_error_1.ExternalHostError(err);
            }
        }
        else {
            logger_1.logger.debug({ repository_fork: config.repository }, 'Created fork');
            existingRepos.push(config.repository);
            // Wait an arbitrary 30s to hopefully give GitHub enough time for forking to complete
            await (0, delay_1.default)(30000);
        }
    }
    const parsedEndpoint = url_1.default.parse(platformConfig.endpoint);
    // istanbul ignore else
    if (forkMode) {
        logger_1.logger.debug('Using forkToken for git init');
        parsedEndpoint.auth = config.forkToken;
    }
    else {
        const tokenType = ((_f = opts.token) === null || _f === void 0 ? void 0 : _f.startsWith('x-access-token:'))
            ? 'app'
            : 'personal access';
        logger_1.logger.debug(`Using ${tokenType} token for git init`);
        parsedEndpoint.auth = opts.token;
    }
    parsedEndpoint.host = parsedEndpoint.host.replace('api.github.com', 'github.com');
    parsedEndpoint.pathname = config.repository + '.git';
    const url = url_1.default.format(parsedEndpoint);
    await git.initRepo({
        ...config,
        url,
    });
    const repoConfig = {
        defaultBranch: config.defaultBranch,
        isFork: repo.isFork === true,
    };
    return repoConfig;
}
exports.initRepo = initRepo;
async function getRepoForceRebase() {
    if (config.repoForceRebase === undefined) {
        try {
            config.repoForceRebase = false;
            const branchProtection = await getBranchProtection(config.defaultBranch);
            logger_1.logger.debug('Found branch protection');
            if (branchProtection.required_pull_request_reviews) {
                logger_1.logger.debug('Branch protection: PR Reviews are required before merging');
                config.prReviewsRequired = true;
            }
            if (branchProtection.required_status_checks) {
                if (branchProtection.required_status_checks.strict) {
                    logger_1.logger.debug('Branch protection: PRs must be up-to-date before merging');
                    config.repoForceRebase = true;
                }
            }
            if (branchProtection.restrictions) {
                logger_1.logger.debug({
                    users: branchProtection.restrictions.users,
                    teams: branchProtection.restrictions.teams,
                }, 'Branch protection: Pushing to branch is restricted');
                config.pushProtection = true;
            }
        }
        catch (err) {
            if (err.statusCode === 404) {
                logger_1.logger.debug(`No branch protection found`);
            }
            else if (err.message === error_messages_1.PLATFORM_INTEGRATION_UNAUTHORIZED ||
                err.statusCode === 403) {
                logger_1.logger.debug('Branch protection: Do not have permissions to detect branch protection');
            }
            else {
                throw err;
            }
        }
    }
    return config.repoForceRebase;
}
exports.getRepoForceRebase = getRepoForceRebase;
async function getClosedPrs() {
    if (!config.closedPrList) {
        config.closedPrList = {};
        try {
            // prettier-ignore
            const nodes = await githubApi.queryRepoField(graphql_1.closedPrsQuery, 'pullRequests', {
                variables: {
                    owner: config.repositoryOwner,
                    name: config.repositoryName,
                },
            });
            const prNumbers = [];
            // istanbul ignore if
            if (!(nodes === null || nodes === void 0 ? void 0 : nodes.length)) {
                logger_1.logger.debug('getClosedPrs(): no graphql data');
                return {};
            }
            for (const pr of nodes) {
                // https://developer.github.com/v4/object/pullrequest/
                pr.displayNumber = `Pull Request #${pr.number}`;
                pr.state = pr.state.toLowerCase();
                pr.sourceBranch = pr.headRefName;
                delete pr.headRefName;
                pr.comments = pr.comments.nodes.map((comment) => ({
                    id: comment.databaseId,
                    body: comment.body,
                }));
                pr.body = 'dummy body'; // just in case
                config.closedPrList[pr.number] = pr;
                prNumbers.push(pr.number);
            }
            prNumbers.sort();
            logger_1.logger.debug({ prNumbers }, 'Retrieved closed PR list with graphql');
        }
        catch (err) /* istanbul ignore next */ {
            logger_1.logger.warn({ err }, 'getClosedPrs(): error');
        }
    }
    return config.closedPrList;
}
async function getOpenPrs() {
    var _a, _b, _c, _d;
    // The graphql query is supported in the current oldest GHE version 2.19
    if (!config.openPrList) {
        config.openPrList = {};
        try {
            // prettier-ignore
            const nodes = await githubApi.queryRepoField(graphql_1.openPrsQuery, 'pullRequests', {
                variables: {
                    owner: config.repositoryOwner,
                    name: config.repositoryName,
                },
                acceptHeader: 'application/vnd.github.merge-info-preview+json',
            });
            const prNumbers = [];
            // istanbul ignore if
            if (!(nodes === null || nodes === void 0 ? void 0 : nodes.length)) {
                logger_1.logger.debug('getOpenPrs(): no graphql data');
                return {};
            }
            for (const pr of nodes) {
                // https://developer.github.com/v4/object/pullrequest/
                pr.displayNumber = `Pull Request #${pr.number}`;
                pr.state = types_1.PrState.Open;
                pr.sourceBranch = pr.headRefName;
                delete pr.headRefName;
                pr.targetBranch = pr.baseRefName;
                delete pr.baseRefName;
                // https://developer.github.com/v4/enum/mergeablestate
                const canMergeStates = ['BEHIND', 'CLEAN', 'HAS_HOOKS', 'UNSTABLE'];
                const hasNegativeReview = ((_b = (_a = pr.reviews) === null || _a === void 0 ? void 0 : _a.nodes) === null || _b === void 0 ? void 0 : _b.length) > 0;
                // istanbul ignore if
                if (hasNegativeReview) {
                    pr.canMerge = false;
                    pr.canMergeReason = `hasNegativeReview`;
                }
                else if (canMergeStates.includes(pr.mergeStateStatus)) {
                    pr.canMerge = true;
                }
                else if (config.forkToken && pr.mergeStateStatus === 'BLOCKED') {
                    // The main token can't merge but maybe the forking token can
                    // istanbul ignore next
                    pr.canMerge = true;
                }
                else {
                    pr.canMerge = false;
                    pr.canMergeReason = `mergeStateStatus = ${pr.mergeStateStatus}`;
                }
                // https://developer.github.com/v4/enum/mergestatestatus
                if (pr.mergeStateStatus === 'DIRTY') {
                    pr.isConflicted = true;
                }
                else {
                    pr.isConflicted = false;
                }
                if (pr.labels) {
                    pr.labels = pr.labels.nodes.map((label) => label.name);
                }
                pr.hasAssignees = !!(((_c = pr.assignees) === null || _c === void 0 ? void 0 : _c.totalCount) > 0);
                delete pr.assignees;
                pr.hasReviewers = !!(((_d = pr.reviewRequests) === null || _d === void 0 ? void 0 : _d.totalCount) > 0);
                delete pr.reviewRequests;
                delete pr.mergeable;
                delete pr.mergeStateStatus;
                delete pr.commits;
                config.openPrList[pr.number] = pr;
                prNumbers.push(pr.number);
            }
            prNumbers.sort();
            logger_1.logger.trace({ prNumbers }, 'Retrieved open PR list with graphql');
        }
        catch (err) /* istanbul ignore next */ {
            logger_1.logger.warn({ err }, 'getOpenPrs(): error');
        }
    }
    return config.openPrList;
}
// Gets details for a PR
async function getPr(prNo) {
    if (!prNo) {
        return null;
    }
    const openPrs = await getOpenPrs();
    const openPr = openPrs[prNo];
    if (openPr) {
        logger_1.logger.debug('Returning from graphql open PR list');
        return openPr;
    }
    const closedPrs = await getClosedPrs();
    const closedPr = closedPrs[prNo];
    if (closedPr) {
        logger_1.logger.debug('Returning from graphql closed PR list');
        return closedPr;
    }
    logger_1.logger.debug({ prNo }, 'PR not found in open or closed PRs list - trying to fetch it directly');
    const pr = (await githubApi.getJson(`repos/${config.parentRepo || config.repository}/pulls/${prNo}`)).body;
    if (!pr) {
        return null;
    }
    // Harmonise PR values
    pr.displayNumber = `Pull Request #${pr.number}`;
    if (pr.state === types_1.PrState.Open) {
        pr.sourceBranch = pr.head ? pr.head.ref : undefined;
        pr.sha = pr.head ? pr.head.sha : undefined;
        if (pr.mergeable === true) {
            pr.canMerge = true;
        }
        else {
            pr.canMerge = false;
            pr.canMergeReason = `mergeable = ${pr.mergeable}`;
        }
        if (pr.mergeable_state === 'dirty') {
            logger_1.logger.debug({ prNo }, 'PR state is dirty so unmergeable');
            pr.isConflicted = true;
        }
    }
    return pr;
}
exports.getPr = getPr;
function matchesState(state, desiredState) {
    if (desiredState === types_1.PrState.All) {
        return true;
    }
    if (desiredState.startsWith('!')) {
        return state !== desiredState.substring(1);
    }
    return state === desiredState;
}
async function getPrList() {
    logger_1.logger.trace('getPrList()');
    if (!config.prList) {
        logger_1.logger.debug('Retrieving PR list');
        let prList;
        try {
            prList = (await githubApi.getJson(`repos/${config.parentRepo || config.repository}/pulls?per_page=100&state=all`, { paginate: true })).body;
        }
        catch (err) /* istanbul ignore next */ {
            logger_1.logger.debug({ err }, 'getPrList err');
            throw new external_host_error_1.ExternalHostError(err, "github" /* Github */);
        }
        config.prList = prList
            .filter((pr) => {
            var _a;
            return config.forkMode ||
                config.ignorePrAuthor ||
                (((_a = pr === null || pr === void 0 ? void 0 : pr.user) === null || _a === void 0 ? void 0 : _a.login) && (config === null || config === void 0 ? void 0 : config.renovateUsername)
                    ? pr.user.login === config.renovateUsername
                    : true);
        })
            .map((pr) => {
            var _a, _b, _c;
            return ({
                number: pr.number,
                sourceBranch: pr.head.ref,
                sha: pr.head.sha,
                title: pr.title,
                state: pr.state === types_1.PrState.Closed && ((_a = pr.merged_at) === null || _a === void 0 ? void 0 : _a.length)
                    ? /* istanbul ignore next */ types_1.PrState.Merged
                    : pr.state,
                createdAt: pr.created_at,
                closedAt: pr.closed_at,
                sourceRepo: (_c = (_b = pr.head) === null || _b === void 0 ? void 0 : _b.repo) === null || _c === void 0 ? void 0 : _c.full_name,
            });
        });
        logger_1.logger.debug(`Retrieved ${config.prList.length} Pull Requests`);
    }
    return config.prList;
}
exports.getPrList = getPrList;
async function findPr({ branchName, prTitle, state = types_1.PrState.All, }) {
    logger_1.logger.debug(`findPr(${branchName}, ${prTitle}, ${state})`);
    const prList = await getPrList();
    const pr = prList.find((p) => p.sourceBranch === branchName &&
        (!prTitle || p.title === prTitle) &&
        matchesState(p.state, state) &&
        (config.forkMode || config.repository === p.sourceRepo) // #5188
    );
    if (pr) {
        logger_1.logger.debug(`Found PR #${pr.number}`);
    }
    return pr;
}
exports.findPr = findPr;
const REOPEN_THRESHOLD_MILLIS = 1000 * 60 * 60 * 24 * 7;
// Returns the Pull Request for a branch. Null if not exists.
async function getBranchPr(branchName) {
    var _a, _b;
    // istanbul ignore if
    if (config.branchPrs[branchName]) {
        return config.branchPrs[branchName];
    }
    logger_1.logger.debug(`getBranchPr(${branchName})`);
    const openPr = await findPr({
        branchName,
        state: types_1.PrState.Open,
    });
    if (openPr) {
        config.branchPrs[branchName] = await getPr(openPr.number);
        return config.branchPrs[branchName];
    }
    const autoclosedPr = await findPr({
        branchName,
        state: types_1.PrState.Closed,
    });
    if (((_a = autoclosedPr === null || autoclosedPr === void 0 ? void 0 : autoclosedPr.title) === null || _a === void 0 ? void 0 : _a.endsWith(' - autoclosed')) &&
        (autoclosedPr === null || autoclosedPr === void 0 ? void 0 : autoclosedPr.closedAt)) {
        const closedMillisAgo = luxon_1.DateTime.fromISO(autoclosedPr.closedAt)
            .diffNow()
            .negate()
            .toMillis();
        if (closedMillisAgo > REOPEN_THRESHOLD_MILLIS) {
            return null;
        }
        logger_1.logger.debug({ autoclosedPr }, 'Found autoclosed PR for branch');
        const { sha, number } = autoclosedPr;
        try {
            await githubApi.postJson(`repos/${config.repository}/git/refs`, {
                body: { ref: `refs/heads/${branchName}`, sha },
            });
            logger_1.logger.debug({ branchName, sha }, 'Recreated autoclosed branch');
        }
        catch (err) {
            logger_1.logger.debug('Could not recreate autoclosed branch - skipping reopen');
            return null;
        }
        try {
            const title = autoclosedPr.title.replace((0, regex_1.regEx)(/ - autoclosed$/), '');
            await githubApi.patchJson(`repos/${config.repository}/pulls/${number}`, {
                body: {
                    state: 'open',
                    title,
                },
            });
            logger_1.logger.info({ branchName, title, number }, 'Successfully reopened autoclosed PR');
        }
        catch (err) {
            logger_1.logger.debug('Could not reopen autoclosed PR');
            return null;
        }
        delete config.openPrList; // So that it gets refreshed
        (_b = config.closedPrList) === null || _b === void 0 ? true : delete _b[number]; // So that it's no longer found in the closed list
        config.branchPrs[branchName] = await getPr(number);
        return config.branchPrs[branchName];
    }
    return null;
}
exports.getBranchPr = getBranchPr;
async function getStatus(branchName, useCache = true) {
    const commitStatusUrl = `repos/${config.repository}/commits/${escapeHash(branchName)}/status`;
    return (await githubApi.getJson(commitStatusUrl, { useCache })).body;
}
// Returns the combined status for a branch.
async function getBranchStatus(branchName) {
    var _a;
    logger_1.logger.debug(`getBranchStatus(${branchName})`);
    let commitStatus;
    try {
        commitStatus = await getStatus(branchName);
    }
    catch (err) /* istanbul ignore next */ {
        if (err.statusCode === 404) {
            logger_1.logger.debug('Received 404 when checking branch status, assuming that branch has been deleted');
            throw new Error(error_messages_1.REPOSITORY_CHANGED);
        }
        logger_1.logger.debug('Unknown error when checking branch status');
        throw err;
    }
    logger_1.logger.debug({ state: commitStatus.state, statuses: commitStatus.statuses }, 'branch status check result');
    let checkRuns = [];
    // API is supported in oldest available GHE version 2.19
    try {
        const checkRunsUrl = `repos/${config.repository}/commits/${escapeHash(branchName)}/check-runs?per_page=100`;
        const opts = {
            headers: {
                accept: 'application/vnd.github.antiope-preview+json',
            },
            paginate: true,
            paginationField: 'check_runs',
        };
        const checkRunsRaw = (await githubApi.getJson(checkRunsUrl, opts)).body;
        if ((_a = checkRunsRaw.check_runs) === null || _a === void 0 ? void 0 : _a.length) {
            checkRuns = checkRunsRaw.check_runs.map((run) => ({
                name: run.name,
                status: run.status,
                conclusion: run.conclusion,
            }));
            logger_1.logger.debug({ checkRuns }, 'check runs result');
        }
        else {
            // istanbul ignore next
            logger_1.logger.debug({ result: checkRunsRaw }, 'No check runs found');
        }
    }
    catch (err) /* istanbul ignore next */ {
        if (err instanceof external_host_error_1.ExternalHostError) {
            throw err;
        }
        if (err.statusCode === 403 ||
            err.message === error_messages_1.PLATFORM_INTEGRATION_UNAUTHORIZED) {
            logger_1.logger.debug('No permission to view check runs');
        }
        else {
            logger_1.logger.warn({ err }, 'Error retrieving check runs');
        }
    }
    if (checkRuns.length === 0) {
        if (commitStatus.state === 'success') {
            return types_1.BranchStatus.green;
        }
        if (commitStatus.state === 'failure') {
            return types_1.BranchStatus.red;
        }
        return types_1.BranchStatus.yellow;
    }
    if (commitStatus.state === 'failure' ||
        checkRuns.some((run) => run.conclusion === 'failure')) {
        return types_1.BranchStatus.red;
    }
    if ((commitStatus.state === 'success' || commitStatus.statuses.length === 0) &&
        checkRuns.every((run) => ['skipped', 'neutral', 'success'].includes(run.conclusion))) {
        return types_1.BranchStatus.green;
    }
    return types_1.BranchStatus.yellow;
}
exports.getBranchStatus = getBranchStatus;
async function getStatusCheck(branchName, useCache = true) {
    const branchCommit = git.getBranchCommit(branchName);
    const url = `repos/${config.repository}/commits/${branchCommit}/statuses`;
    return (await githubApi.getJson(url, { useCache })).body;
}
const githubToRenovateStatusMapping = {
    success: types_1.BranchStatus.green,
    error: types_1.BranchStatus.red,
    failure: types_1.BranchStatus.red,
    pending: types_1.BranchStatus.yellow,
};
async function getBranchStatusCheck(branchName, context) {
    try {
        const res = await getStatusCheck(branchName);
        for (const check of res) {
            if (check.context === context) {
                return (githubToRenovateStatusMapping[check.state] || types_1.BranchStatus.yellow);
            }
        }
        return null;
    }
    catch (err) /* istanbul ignore next */ {
        if (err.statusCode === 404) {
            logger_1.logger.debug('Commit not found when checking statuses');
            throw new Error(error_messages_1.REPOSITORY_CHANGED);
        }
        throw err;
    }
}
exports.getBranchStatusCheck = getBranchStatusCheck;
async function setBranchStatus({ branchName, context, description, state, url: targetUrl, }) {
    // istanbul ignore if
    if (config.parentRepo) {
        logger_1.logger.debug('Cannot set branch status when in forking mode');
        return;
    }
    const existingStatus = await getBranchStatusCheck(branchName, context);
    if (existingStatus === state) {
        return;
    }
    logger_1.logger.debug({ branch: branchName, context, state }, 'Setting branch status');
    let url;
    try {
        const branchCommit = git.getBranchCommit(branchName);
        url = `repos/${config.repository}/statuses/${branchCommit}`;
        const renovateToGitHubStateMapping = {
            green: 'success',
            yellow: 'pending',
            red: 'failure',
        };
        const options = {
            state: renovateToGitHubStateMapping[state],
            description,
            context,
        };
        if (targetUrl) {
            options.target_url = targetUrl;
        }
        await githubApi.postJson(url, { body: options });
        // update status cache
        await getStatus(branchName, false);
        await getStatusCheck(branchName, false);
    }
    catch (err) /* istanbul ignore next */ {
        logger_1.logger.debug({ err, url }, 'Caught error setting branch status - aborting');
        throw new Error(error_messages_1.REPOSITORY_CHANGED);
    }
}
exports.setBranchStatus = setBranchStatus;
// Issue
/* istanbul ignore next */
async function getIssues() {
    const result = await githubApi.queryRepoField(graphql_1.getIssuesQuery, 'issues', {
        variables: {
            owner: config.repositoryOwner,
            name: config.repositoryName,
            user: config.renovateUsername,
        },
    });
    logger_1.logger.debug(`Retrieved ${result.length} issues`);
    return result.map((issue) => ({
        ...issue,
        state: issue.state.toLowerCase(),
    }));
}
async function getIssueList() {
    // istanbul ignore if
    if (config.hasIssuesEnabled === false) {
        return [];
    }
    if (!config.issueList) {
        logger_1.logger.debug('Retrieving issueList');
        config.issueList = await getIssues();
    }
    return config.issueList;
}
exports.getIssueList = getIssueList;
async function getIssue(number, useCache = true) {
    // istanbul ignore if
    if (config.hasIssuesEnabled === false) {
        return null;
    }
    try {
        const issueBody = (await githubApi.getJson(`repos/${config.parentRepo || config.repository}/issues/${number}`, { useCache })).body.body;
        return {
            number,
            body: issueBody,
        };
    }
    catch (err) /* istanbul ignore next */ {
        logger_1.logger.debug({ err, number }, 'Error getting issue');
        return null;
    }
}
exports.getIssue = getIssue;
async function findIssue(title) {
    logger_1.logger.debug(`findIssue(${title})`);
    const [issue] = (await getIssueList()).filter((i) => i.state === 'open' && i.title === title);
    if (!issue) {
        return null;
    }
    logger_1.logger.debug(`Found issue ${issue.number}`);
    return getIssue(issue.number);
}
exports.findIssue = findIssue;
async function closeIssue(issueNumber) {
    logger_1.logger.debug(`closeIssue(${issueNumber})`);
    await githubApi.patchJson(`repos/${config.parentRepo || config.repository}/issues/${issueNumber}`, {
        body: { state: 'closed' },
    });
}
async function ensureIssue({ title, reuseTitle, body: rawBody, labels, once = false, shouldReOpen = true, }) {
    var _a, _b;
    logger_1.logger.debug(`ensureIssue(${title})`);
    // istanbul ignore if
    if (config.hasIssuesEnabled === false) {
        logger_1.logger.info('Cannot ensure issue because issues are disabled in this repository');
        return null;
    }
    const body = (0, sanitize_1.sanitize)(rawBody);
    try {
        const issueList = await getIssueList();
        let issues = issueList.filter((i) => i.title === title);
        if (!issues.length) {
            issues = issueList.filter((i) => i.title === reuseTitle);
            if (issues.length) {
                logger_1.logger.debug({ reuseTitle, title }, 'Reusing issue title');
            }
        }
        if (issues.length) {
            let issue = issues.find((i) => i.state === 'open');
            if (!issue) {
                if (once) {
                    logger_1.logger.debug('Issue already closed - skipping recreation');
                    return null;
                }
                if (shouldReOpen) {
                    logger_1.logger.debug('Reopening previously closed issue');
                }
                issue = issues[issues.length - 1];
            }
            for (const i of issues) {
                if (i.state === 'open' && i.number !== issue.number) {
                    logger_1.logger.warn(`Closing duplicate issue ${i.number}`);
                    await closeIssue(i.number);
                }
            }
            const issueBody = (await githubApi.getJson(`repos/${config.parentRepo || config.repository}/issues/${issue.number}`)).body.body;
            if (issue.title === title &&
                issueBody === body &&
                issue.state === 'open') {
                logger_1.logger.debug('Issue is open and up to date - nothing to do');
                return null;
            }
            if (shouldReOpen) {
                logger_1.logger.debug('Patching issue');
                const data = { body, state: 'open', title };
                if (labels) {
                    data.labels = labels;
                }
                await githubApi.patchJson(`repos/${config.parentRepo || config.repository}/issues/${issue.number}`, {
                    body: data,
                });
                logger_1.logger.debug('Issue updated');
                return 'updated';
            }
        }
        await githubApi.postJson(`repos/${config.parentRepo || config.repository}/issues`, {
            body: {
                title,
                body,
                labels: labels || [],
            },
        });
        logger_1.logger.info('Issue created');
        // reset issueList so that it will be fetched again as-needed
        delete config.issueList;
        return 'created';
    }
    catch (err) /* istanbul ignore next */ {
        if ((_b = (_a = err.body) === null || _a === void 0 ? void 0 : _a.message) === null || _b === void 0 ? void 0 : _b.startsWith('Issues are disabled for this repo')) {
            logger_1.logger.debug(`Issues are disabled, so could not create issue: ${title}`);
        }
        else {
            logger_1.logger.warn({ err }, 'Could not ensure issue');
        }
    }
    return null;
}
exports.ensureIssue = ensureIssue;
async function ensureIssueClosing(title) {
    logger_1.logger.trace(`ensureIssueClosing(${title})`);
    // istanbul ignore if
    if (config.hasIssuesEnabled === false) {
        logger_1.logger.info('Cannot ensure issue because issues are disabled in this repository');
        return;
    }
    const issueList = await getIssueList();
    for (const issue of issueList) {
        if (issue.state === 'open' && issue.title === title) {
            await closeIssue(issue.number);
            logger_1.logger.debug({ number: issue.number }, 'Issue closed');
        }
    }
}
exports.ensureIssueClosing = ensureIssueClosing;
async function addAssignees(issueNo, assignees) {
    logger_1.logger.debug(`Adding assignees '${assignees.join(', ')}' to #${issueNo}`);
    const repository = config.parentRepo || config.repository;
    await githubApi.postJson(`repos/${repository}/issues/${issueNo}/assignees`, {
        body: {
            assignees,
        },
    });
}
exports.addAssignees = addAssignees;
async function addReviewers(prNo, reviewers) {
    logger_1.logger.debug(`Adding reviewers '${reviewers.join(', ')}' to #${prNo}`);
    const userReviewers = reviewers.filter((e) => !e.startsWith('team:'));
    const teamReviewers = reviewers
        .filter((e) => e.startsWith('team:'))
        .map((e) => e.replace((0, regex_1.regEx)(/^team:/), '')); // TODO #12071
    try {
        await githubApi.postJson(`repos/${config.parentRepo || config.repository}/pulls/${prNo}/requested_reviewers`, {
            body: {
                reviewers: userReviewers,
                team_reviewers: teamReviewers,
            },
        });
    }
    catch (err) /* istanbul ignore next */ {
        logger_1.logger.warn({ err }, 'Failed to assign reviewer');
    }
}
exports.addReviewers = addReviewers;
async function addLabels(issueNo, labels) {
    logger_1.logger.debug(`Adding labels '${labels === null || labels === void 0 ? void 0 : labels.join(', ')}' to #${issueNo}`);
    const repository = config.parentRepo || config.repository;
    if (is_1.default.array(labels) && labels.length) {
        await githubApi.postJson(`repos/${repository}/issues/${issueNo}/labels`, {
            body: labels,
        });
    }
}
async function deleteLabel(issueNo, label) {
    logger_1.logger.debug(`Deleting label ${label} from #${issueNo}`);
    const repository = config.parentRepo || config.repository;
    try {
        await githubApi.deleteJson(`repos/${repository}/issues/${issueNo}/labels/${label}`);
    }
    catch (err) /* istanbul ignore next */ {
        logger_1.logger.warn({ err, issueNo, label }, 'Failed to delete label');
    }
}
exports.deleteLabel = deleteLabel;
async function addComment(issueNo, body) {
    // POST /repos/:owner/:repo/issues/:number/comments
    await githubApi.postJson(`repos/${config.parentRepo || config.repository}/issues/${issueNo}/comments`, {
        body: { body },
    });
}
async function editComment(commentId, body) {
    // PATCH /repos/:owner/:repo/issues/comments/:id
    await githubApi.patchJson(`repos/${config.parentRepo || config.repository}/issues/comments/${commentId}`, {
        body: { body },
    });
}
async function deleteComment(commentId) {
    // DELETE /repos/:owner/:repo/issues/comments/:id
    await githubApi.deleteJson(`repos/${config.parentRepo || config.repository}/issues/comments/${commentId}`);
}
async function getComments(issueNo) {
    const pr = (await getClosedPrs())[issueNo];
    if (pr) {
        logger_1.logger.debug('Returning closed PR list comments');
        return pr.comments;
    }
    // GET /repos/:owner/:repo/issues/:number/comments
    logger_1.logger.debug(`Getting comments for #${issueNo}`);
    const url = `repos/${config.parentRepo || config.repository}/issues/${issueNo}/comments?per_page=100`;
    try {
        const comments = (await githubApi.getJson(url, {
            paginate: true,
        })).body;
        logger_1.logger.debug(`Found ${comments.length} comments`);
        return comments;
    }
    catch (err) /* istanbul ignore next */ {
        if (err.statusCode === 404) {
            logger_1.logger.debug('404 response when retrieving comments');
            throw new external_host_error_1.ExternalHostError(err, "github" /* Github */);
        }
        throw err;
    }
}
async function ensureComment({ number, topic, content, }) {
    var _a, _b;
    const sanitizedContent = (0, sanitize_1.sanitize)(content);
    try {
        const comments = await getComments(number);
        let body;
        let commentId = null;
        let commentNeedsUpdating = false;
        if (topic) {
            logger_1.logger.debug(`Ensuring comment "${topic}" in #${number}`);
            body = `### ${topic}\n\n${sanitizedContent}`;
            comments.forEach((comment) => {
                if (comment.body.startsWith(`### ${topic}\n\n`)) {
                    commentId = comment.id;
                    commentNeedsUpdating = comment.body !== body;
                }
            });
        }
        else {
            logger_1.logger.debug(`Ensuring content-only comment in #${number}`);
            body = `${sanitizedContent}`;
            comments.forEach((comment) => {
                if (comment.body === body) {
                    commentId = comment.id;
                    commentNeedsUpdating = false;
                }
            });
        }
        if (!commentId) {
            await addComment(number, body);
            logger_1.logger.info({ repository: config.repository, issueNo: number, topic }, 'Comment added');
        }
        else if (commentNeedsUpdating) {
            await editComment(commentId, body);
            logger_1.logger.debug({ repository: config.repository, issueNo: number }, 'Comment updated');
        }
        else {
            logger_1.logger.debug('Comment is already update-to-date');
        }
        return true;
    }
    catch (err) /* istanbul ignore next */ {
        if (err instanceof external_host_error_1.ExternalHostError) {
            throw err;
        }
        if ((_b = (_a = err.body) === null || _a === void 0 ? void 0 : _a.message) === null || _b === void 0 ? void 0 : _b.includes('is locked')) {
            logger_1.logger.debug('Issue is locked - cannot add comment');
        }
        else {
            logger_1.logger.warn({ err }, 'Error ensuring comment');
        }
        return false;
    }
}
exports.ensureComment = ensureComment;
async function ensureCommentRemoval({ number: issueNo, topic, content, }) {
    var _a, _b;
    logger_1.logger.trace(`Ensuring comment "${topic || content}" in #${issueNo} is removed`);
    const comments = await getComments(issueNo);
    let commentId = null;
    const byTopic = (comment) => comment.body.startsWith(`### ${topic}\n\n`);
    const byContent = (comment) => comment.body.trim() === content;
    if (topic) {
        commentId = (_a = comments.find(byTopic)) === null || _a === void 0 ? void 0 : _a.id;
    }
    else if (content) {
        commentId = (_b = comments.find(byContent)) === null || _b === void 0 ? void 0 : _b.id;
    }
    try {
        if (commentId) {
            logger_1.logger.debug({ issueNo }, 'Removing comment');
            await deleteComment(commentId);
        }
    }
    catch (err) /* istanbul ignore next */ {
        logger_1.logger.warn({ err }, 'Error deleting comment');
    }
}
exports.ensureCommentRemoval = ensureCommentRemoval;
// Pull Request
async function tryPrAutomerge(prNumber, prNodeId, platformOptions) {
    var _a;
    if (platformConfig.isGhe || !(platformOptions === null || platformOptions === void 0 ? void 0 : platformOptions.usePlatformAutomerge)) {
        return;
    }
    if (!config.autoMergeAllowed) {
        logger_1.logger.debug({ prNumber }, 'GitHub-native automerge: not enabled in repo settings');
        return;
    }
    try {
        const mergeMethod = ((_a = config.mergeMethod) === null || _a === void 0 ? void 0 : _a.toUpperCase()) || 'MERGE';
        const variables = { pullRequestId: prNodeId, mergeMethod };
        const queryOptions = { variables };
        const { errors } = await githubApi.requestGraphql(graphql_1.enableAutoMergeMutation, queryOptions);
        if (errors) {
            logger_1.logger.debug({ prNumber, errors }, 'GitHub-native automerge: fail');
            return;
        }
        logger_1.logger.debug({ prNumber }, 'GitHub-native automerge: success');
    }
    catch (err) {
        logger_1.logger.warn({ prNumber, err }, 'GitHub-native automerge: REST API error');
    }
}
// Creates PR and returns PR number
async function createPr({ sourceBranch, targetBranch, prTitle: title, prBody: rawBody, labels, draftPR = false, platformOptions, }) {
    const body = (0, sanitize_1.sanitize)(rawBody);
    const base = targetBranch;
    // Include the repository owner to handle forkMode and regular mode
    const head = `${config.repository.split('/')[0]}:${sourceBranch}`;
    const options = {
        body: {
            title,
            head,
            base,
            body,
            draft: draftPR,
        },
    };
    // istanbul ignore if
    if (config.forkToken) {
        options.token = config.forkToken;
        options.body.maintainer_can_modify = true;
    }
    logger_1.logger.debug({ title, head, base, draft: draftPR }, 'Creating PR');
    const pr = (await githubApi.postJson(`repos/${config.parentRepo || config.repository}/pulls`, options)).body;
    logger_1.logger.debug({ branch: sourceBranch, pr: pr.number, draft: draftPR }, 'PR created');
    // istanbul ignore if
    if (config.prList) {
        config.prList.push(pr);
    }
    pr.displayNumber = `Pull Request #${pr.number}`;
    pr.sourceBranch = sourceBranch;
    pr.sourceRepo = pr.head.repo.full_name;
    await addLabels(pr.number, labels);
    await tryPrAutomerge(pr.number, pr.node_id, platformOptions);
    return pr;
}
exports.createPr = createPr;
async function updatePr({ number: prNo, prTitle: title, prBody: rawBody, state, }) {
    logger_1.logger.debug(`updatePr(${prNo}, ${title}, body)`);
    const body = (0, sanitize_1.sanitize)(rawBody);
    const patchBody = { title };
    if (body) {
        patchBody.body = body;
    }
    if (state) {
        patchBody.state = state;
    }
    const options = {
        body: patchBody,
    };
    // istanbul ignore if
    if (config.forkToken) {
        options.token = config.forkToken;
    }
    try {
        await githubApi.patchJson(`repos/${config.parentRepo || config.repository}/pulls/${prNo}`, options);
        logger_1.logger.debug({ pr: prNo }, 'PR updated');
    }
    catch (err) /* istanbul ignore next */ {
        if (err instanceof external_host_error_1.ExternalHostError) {
            throw err;
        }
        logger_1.logger.warn({ err }, 'Error updating PR');
    }
}
exports.updatePr = updatePr;
async function mergePr({ branchName, id: prNo, }) {
    logger_1.logger.debug(`mergePr(${prNo}, ${branchName})`);
    // istanbul ignore if
    if (config.prReviewsRequired) {
        logger_1.logger.debug({ branch: branchName, prNo }, 'Branch protection: Attempting to merge PR when PR reviews are enabled');
        const repository = config.parentRepo || config.repository;
        const reviews = await githubApi.getJson(`repos/${repository}/pulls/${prNo}/reviews`);
        const isApproved = reviews.body.some((review) => review.state === 'APPROVED');
        if (!isApproved) {
            logger_1.logger.debug({ branch: branchName, prNo }, 'Branch protection: Cannot automerge PR until there is an approving review');
            return false;
        }
        logger_1.logger.debug('Found approving reviews');
    }
    const url = `repos/${config.parentRepo || config.repository}/pulls/${prNo}/merge`;
    const options = {
        body: {},
    };
    // istanbul ignore if
    if (config.forkToken) {
        options.token = config.forkToken;
    }
    let automerged = false;
    let automergeResult;
    if (config.mergeMethod) {
        // This path is taken if we have auto-detected the allowed merge types from the repo
        options.body.merge_method = config.mergeMethod;
        try {
            logger_1.logger.debug({ options, url }, `mergePr`);
            automergeResult = await githubApi.putJson(url, options);
            automerged = true;
        }
        catch (err) {
            if (err.statusCode === 404 || err.statusCode === 405) {
                // istanbul ignore next
                logger_1.logger.debug({ response: err.response ? err.response.body : undefined }, 'GitHub blocking PR merge -- will keep trying');
            }
            else {
                logger_1.logger.warn({ err }, `Failed to ${config.mergeMethod} merge PR`);
                return false;
            }
        }
    }
    if (!automerged) {
        // We need to guess the merge method and try squash -> rebase -> merge
        options.body.merge_method = 'rebase';
        try {
            logger_1.logger.debug({ options, url }, `mergePr`);
            automergeResult = await githubApi.putJson(url, options);
        }
        catch (err1) {
            logger_1.logger.debug({ err: err1 }, `Failed to rebase merge PR`);
            try {
                options.body.merge_method = 'squash';
                logger_1.logger.debug({ options, url }, `mergePr`);
                automergeResult = await githubApi.putJson(url, options);
            }
            catch (err2) {
                logger_1.logger.debug({ err: err2 }, `Failed to merge squash PR`);
                try {
                    options.body.merge_method = 'merge';
                    logger_1.logger.debug({ options, url }, `mergePr`);
                    automergeResult = await githubApi.putJson(url, options);
                }
                catch (err3) {
                    logger_1.logger.debug({ err: err3 }, `Failed to merge commit PR`);
                    logger_1.logger.info({ pr: prNo }, 'All merge attempts failed');
                    return false;
                }
            }
        }
    }
    logger_1.logger.debug({ automergeResult: automergeResult.body, pr: prNo }, 'PR merged');
    return true;
}
exports.mergePr = mergePr;
function massageMarkdown(input) {
    if (platformConfig.isGhe) {
        return (0, pr_body_1.smartTruncate)(input, 60000);
    }
    const massagedInput = (0, massage_markdown_links_1.massageMarkdownLinks)(input)
        // to be safe, replace all github.com links with renovatebot redirector
        .replace((0, regex_1.regEx)(/href="https?:\/\/github.com\//g), 'href="https://togithub.com/')
        .replace((0, regex_1.regEx)(/]\(https:\/\/github\.com\//g), '](https://togithub.com/')
        .replace((0, regex_1.regEx)(/]: https:\/\/github\.com\//g), ']: https://togithub.com/');
    return (0, pr_body_1.smartTruncate)(massagedInput, 60000);
}
exports.massageMarkdown = massageMarkdown;
async function getVulnerabilityAlerts() {
    let vulnerabilityAlerts;
    try {
        vulnerabilityAlerts = await githubApi.queryRepoField(graphql_1.vulnerabilityAlertsQuery, 'vulnerabilityAlerts', {
            variables: { owner: config.repositoryOwner, name: config.repositoryName },
            paginate: false,
            acceptHeader: 'application/vnd.github.vixen-preview+json',
        });
    }
    catch (err) {
        logger_1.logger.debug({ err }, 'Error retrieving vulnerability alerts');
        logger_1.logger.warn({
            url: 'https://docs.renovatebot.com/configuration-options/#vulnerabilityalerts',
        }, 'Cannot access vulnerability alerts. Please ensure permissions have been granted.');
    }
    let alerts = [];
    try {
        if (vulnerabilityAlerts === null || vulnerabilityAlerts === void 0 ? void 0 : vulnerabilityAlerts.length) {
            alerts = vulnerabilityAlerts.map((edge) => edge.node);
            const shortAlerts = {};
            if (alerts.length) {
                logger_1.logger.trace({ alerts }, 'GitHub vulnerability details');
                for (const alert of alerts) {
                    const { package: { name, ecosystem }, vulnerableVersionRange, firstPatchedVersion, } = alert.securityVulnerability;
                    const patch = firstPatchedVersion === null || firstPatchedVersion === void 0 ? void 0 : firstPatchedVersion.identifier;
                    const key = `${ecosystem.toLowerCase()}/${name}`;
                    const range = vulnerableVersionRange;
                    const elem = shortAlerts[key] || {};
                    elem[range] = patch || null;
                    shortAlerts[key] = elem;
                }
                logger_1.logger.debug({ alerts: shortAlerts }, 'GitHub vulnerability details');
            }
        }
        else {
            logger_1.logger.debug('No vulnerability alerts found');
        }
    }
    catch (err) /* istanbul ignore next */ {
        logger_1.logger.error({ err }, 'Error processing vulnerabity alerts');
    }
    return alerts;
}
exports.getVulnerabilityAlerts = getVulnerabilityAlerts;
//# sourceMappingURL=index.js.map